# ğŸ›¡ï¸ ITERA Smart Sentinel

**Sistem Deteksi & Analitik Pelanggaran Helm Real-time**

Real-time helmet violation detection and analytics system for motorcycle riders, combining YOLOv8 object detection, ByteTrack multi-object tracking, and Apache Kafka/Spark streaming.

## Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Pipeline Workflow](#pipeline-workflow)
- [Database Schema](#database-schema)
- [Grafana Dashboard](#grafana-dashboard)
- [Testing](#testing)
- [Documentation](#documentation)

## Overview

ITERA Smart Sentinel detects motorcycle riders without helmets from CCTV/RTSP camera feeds in real time. The system processes video frames through a YOLOv8 detection model, tracks individuals across frames with ByteTrack, confirms violations using temporal consistency logic, streams events through Apache Kafka, and stores results in PostgreSQL for visualization in Grafana dashboards.

The model classifies three object types:

| Class ID | Class Name          | Description                          |
|----------|---------------------|--------------------------------------|
| 0        | `DRIVER_HELMET`     | Motorcycle rider wearing a helmet    |
| 1        | `DRIVER_NO_HELMET`  | Motorcycle rider without a helmet    |
| 2        | `MOTORCYCLE`        | Motorcycle (vehicle)                 |

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Video Source    â”‚â”€â”€â”€â”€â–¶â”‚  YOLOv8      â”‚â”€â”€â”€â”€â–¶â”‚  ByteTrack  â”‚
â”‚  (RTSP / File)  â”‚     â”‚  Detector    â”‚     â”‚  Tracker    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL     â”‚â—€â”€â”€â”€â”€â”‚  Spark       â”‚â—€â”€â”€â”€â”€â”‚  Kafka      â”‚
â”‚  (Supabase)     â”‚     â”‚  Streaming   â”‚     â”‚  Producer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                          â”‚
         â–¼                                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Grafana        â”‚                          â”‚  Violation  â”‚
â”‚  Dashboard      â”‚                          â”‚  Detector   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Data flow:**

1. **Video Capture** â€” Reads frames from an RTSP stream or local video file
2. **YOLOv8 Inference** â€” Detects helmets, no-helmets, and motorcycles per frame
3. **ByteTrack Tracking** â€” Assigns persistent track IDs to detections across frames
4. **Violation Detection** â€” Confirms violations after N consecutive frames of `DRIVER_NO_HELMET` (temporal filtering)
5. **Kafka Streaming** â€” Sends confirmed violation events to a Kafka topic
6. **Spark Processing** â€” Consumes from Kafka, deduplicates, enriches with time dimensions
7. **PostgreSQL Storage** â€” Writes to a Star Schema (fact + dimension tables)
8. **Grafana Visualization** â€” Displays real-time dashboards with KPIs, heatmaps, and trends

## Features

- **Real-time YOLOv8 detection** â€” 3-class helmet/no-helmet/motorcycle detection
- **Multi-object tracking** â€” ByteTrack maintains unique IDs across frames, handles occlusion
- **Temporal violation confirmation** â€” N-frame consecutive detection rule reduces false positives
- **Per-track deduplication** â€” Each track ID emits at most one violation per session
- **Kafka event streaming** â€” High-throughput message delivery (3,700+ messages/sec)
- **Spark Structured Streaming** â€” Micro-batch processing with watermark-based deduplication
- **Star Schema analytics** â€” Denormalized time dimensions for fast Grafana queries
- **RTSP reconnection** â€” Automatic reconnection on stream disconnection
- **Configurable pipeline** â€” All parameters tunable via environment variables
- **Optional display mode** â€” Annotated video output with bounding boxes and FPS overlay

## Tech Stack

| Component            | Technology                                  |
|----------------------|---------------------------------------------|
| Object Detection     | YOLOv8 (Ultralytics)                        |
| Multi-Object Tracking| ByteTrack (via supervision library)          |
| Video Processing     | OpenCV                                      |
| Message Broker       | Apache Kafka (confluent-kafka)               |
| Stream Processing    | Apache Spark Structured Streaming            |
| Database             | PostgreSQL (Supabase)                        |
| Dashboard            | Grafana                                      |
| Configuration        | Pydantic Settings                            |
| Logging              | Loguru                                       |
| Package Manager      | uv                                           |

## Project Structure

```
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py               # Centralized configuration (Pydantic BaseSettings)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ bab4_draft.tex            # Technical documentation (LaTeX)
â”‚   â””â”€â”€ WORKFLOW.md               # Detailed pipeline workflow documentation
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ dashboards/               # Grafana dashboard JSON definitions
â”‚   â””â”€â”€ provisioning/             # Grafana provisioning configuration
â”œâ”€â”€ models/                       # YOLOv8 model weights (best.pt, gitignored)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.sh           # Full system startup script
â”‚   â””â”€â”€ setup_kafka_topics.sh     # Kafka topic initialization
â”œâ”€â”€ spark/
â”‚   â””â”€â”€ stream_processor.py       # Spark Structured Streaming consumer
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 001_create_dimensions.sql # Dimension tables (camera, violation type)
â”‚   â”œâ”€â”€ 002_create_facts.sql      # Fact table with indexes
â”‚   â””â”€â”€ 003_create_views.sql      # Analytical views for Grafana
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ detector/
â”‚   â”‚   â”œâ”€â”€ model.py              # YOLOv8 helmet detector wrapper
â”‚   â”‚   â”œâ”€â”€ tracker.py            # ByteTrack multi-object tracker
â”‚   â”‚   â””â”€â”€ violation.py          # Violation detection logic
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ main.py               # Main pipeline orchestrator
â”‚   â”œâ”€â”€ streaming/
â”‚   â”‚   â”œâ”€â”€ producer.py           # Kafka producer for violation events
â”‚   â”‚   â””â”€â”€ consumer.py           # Kafka consumer (debugging/testing)
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ schemas.py            # Pydantic data models
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_detector.py          # Unit tests
â”‚   â”œâ”€â”€ benchmark_pipeline.py     # Performance benchmarking
â”‚   â””â”€â”€ resource_benchmark.py     # Resource usage analysis
â”œâ”€â”€ .env.example                  # Environment variable template
â”œâ”€â”€ pyproject.toml                # Project metadata and dependencies
â””â”€â”€ uv.lock                       # Dependency lock file
```

## Prerequisites

- **Python** â‰¥ 3.11
- **uv** package manager ([install guide](https://docs.astral.sh/uv/getting-started/installation/))
- **Apache Kafka** (with Zookeeper)
- **Apache Spark** 3.5+ (for stream processing)
- **PostgreSQL** (or Supabase)
- **Grafana** (optional, for dashboards)
- **NVIDIA GPU** with CUDA â‰¥ 7.0 (optional, falls back to CPU)

## Installation

1. **Clone the repository:**

   ```bash
   git clone https://github.com/EgiStr/sistem-cerdas-yolo-bytrack.git
   cd sistem-cerdas-yolo-bytrack
   ```

2. **Install Python dependencies:**

   ```bash
   uv sync
   ```

3. **Configure environment variables:**

   ```bash
   cp .env.example .env
   # Edit .env with your settings (video source, Kafka, database credentials)
   ```

4. **Place the YOLOv8 model:**

   Place your trained `best.pt` model file in the `models/` directory.

5. **Set up the database:**

   Run the SQL scripts in order against your PostgreSQL instance:

   ```bash
   psql -h <host> -U <user> -d <database> -f sql/001_create_dimensions.sql
   psql -h <host> -U <user> -d <database> -f sql/002_create_facts.sql
   psql -h <host> -U <user> -d <database> -f sql/003_create_views.sql
   ```

6. **Set up Kafka topics:**

   ```bash
   bash scripts/setup_kafka_topics.sh
   ```

## Configuration

All settings are managed via environment variables loaded from a `.env` file. See [`.env.example`](.env.example) for all available options.

Key settings:

| Variable                    | Default            | Description                             |
|-----------------------------|--------------------|-----------------------------------------|
| `VIDEO_SOURCE`              | `sample_video.mp4` | RTSP URL or local video file path       |
| `MODEL_PATH`                | `models/best.pt`   | Path to YOLOv8 model weights            |
| `MODEL_CONFIDENCE`          | `0.5`              | Detection confidence threshold           |
| `MODEL_DEVICE`              | `0`                | CUDA device index or `cpu`               |
| `VIOLATION_CONFIRM_FRAMES`  | `3`                | Consecutive frames required to confirm   |
| `KAFKA_BOOTSTRAP_SERVERS`   | `localhost:9092`   | Kafka broker address                     |
| `KAFKA_TOPIC_VIOLATIONS`    | `video.violations` | Kafka topic for violation events         |

## Usage

### Run the detection pipeline

```bash
# Basic usage (with Kafka)
uv run python -m src.pipeline.main --source sample_video.mp4

# With video display window
uv run python -m src.pipeline.main --source sample_video.mp4 --display

# Without Kafka (testing/logging only)
uv run python -m src.pipeline.main --source sample_video.mp4 --no-kafka --display

# Save annotated output to file
uv run python -m src.pipeline.main --source sample_video.mp4 --save-output output.mp4

# RTSP camera stream
uv run python -m src.pipeline.main --source rtsp://admin:password@192.168.1.100:554/stream1
```

### Run Spark stream processor

```bash
/opt/spark/bin/spark-submit \
    --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.8,org.postgresql:postgresql:42.7.1 \
    spark/stream_processor.py
```

### Run the full system

Use the provided startup script:

```bash
bash scripts/run_pipeline.sh
```

This checks prerequisites (Kafka, `.env`), creates Kafka topics, and prints instructions for starting each component.

### Debug Kafka messages

```bash
uv run python -m src.streaming.consumer
```

## Pipeline Workflow

For a detailed description of the pipeline workflow, data flow, and each component, see [docs/WORKFLOW.md](docs/WORKFLOW.md).

### Summary

The pipeline follows a **Detect â†’ Track â†’ Confirm â†’ Stream â†’ Store â†’ Visualize** pattern:

1. **HelmetDetector** (`src/detector/model.py`) â€” Runs YOLOv8 inference on each frame, returns `supervision.Detections`
2. **ObjectTracker** (`src/detector/tracker.py`) â€” Updates ByteTrack with detections, assigns persistent `tracker_id` values
3. **ViolationDetector** (`src/detector/violation.py`) â€” Checks for `DRIVER_NO_HELMET` detections sustained over N consecutive frames, deduplicates by `track_id`
4. **ViolationProducer** (`src/streaming/producer.py`) â€” Serializes `ViolationEvent` to JSON and publishes to Kafka with snappy compression
5. **Spark StreamProcessor** (`spark/stream_processor.py`) â€” Consumes from Kafka, deduplicates within a 30-second watermark window, enriches with time dimensions, writes to PostgreSQL
6. **Grafana Dashboard** â€” Queries PostgreSQL views for real-time KPIs, heatmaps, trends, and violation logs

## Database Schema

The system uses a **Star Schema** design for analytical queries:

**Dimension tables:**
- `dim_camera` â€” Camera metadata (ID, name, location, gate)
- `dim_violation_type` â€” Violation type definitions

**Fact table:**
- `fact_violations` â€” Violation events with embedded time dimensions (hour, day_of_week, time_period) for fast aggregation

**Analytical views:**
- `vw_hourly_violations` â€” Hourly violation counts by camera (heatmap)
- `vw_daily_trend` â€” Daily violation trends (time series)
- `vw_camera_stats` â€” Per-camera statistics (bar chart)
- `vw_peak_hours` â€” Peak hours analysis (hour Ã— day_of_week heatmap)
- `vw_today_summary` â€” Today's KPI summary
- `vw_recent_violations` â€” Latest 100 violations (detail table)

## Grafana Dashboard

The Grafana Safety Dashboard provides six main panels:

1. **KPI Overview** â€” Total violations today, average confidence, average processing latency
2. **Temporal Trend** â€” Time-series chart of hourly violations over 24 hours
3. **Activity Heatmap** â€” Hour Ã— Day matrix showing violation hotspots
4. **Location Distribution** â€” Bar chart comparing violations across cameras/gates
5. **Time Period Distribution** â€” Pie chart of violations by period (Pagi/Siang/Sore/Malam)
6. **Violation Log** â€” Table of recent violations with confidence and track details

Dashboard definitions are stored in `grafana/dashboards/` and can be provisioned automatically via `grafana/provisioning/`.

## Testing

```bash
# Run unit tests
uv run pytest tests/

# Run benchmarks
uv run python tests/benchmark_pipeline.py
uv run python tests/resource_benchmark.py
```

## Documentation

- [Pipeline Workflow Details](docs/WORKFLOW.md) â€” Complete data flow and component documentation
- [Technical Report (LaTeX)](docs/bab4_draft.tex) â€” Experimental results and analysis
- [Environment Configuration](.env.example) â€” All available configuration variables
